{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Exercise2_DogvsCat_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soham-wairkar/CE888/blob/main/LAB7/Exercise2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTh9DiKVslsJ"
      },
      "source": [
        "## Dogs vs. Cats \n",
        "\n",
        "In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n",
        "\n",
        "Ref: https://medium.com/@thegrigorian/rolling-in-the-deep-cnn-c8d3f7108c8c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSBI-_mSSY1g"
      },
      "source": [
        "Get your API Key from Kaggle using following steps:\n",
        "1. Login to [Kaggle](https://www.kaggle.com/) or Register if you don't have account\n",
        "2. Open Dataset (https://www.kaggle.com/c/dogs-vs-cats/rules) and accept terms and condition. \n",
        "3. On the top right corner click on your Icon and go to accounts and press a button \"Create New API Token\". It will download a JSON file containing your username and key. \n",
        "4. Now, paste both below. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmYjhhfMuUVR",
        "outputId": "43270a79-0908-4a97-c9e1-55121b8bc29a"
      },
      "source": [
        "!kaggle -v"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kaggle API 1.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXSOc0tZIGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939b87f0-93ea-4e04-9ec6-2b0fe861e640"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"sohamwairkar\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"33ac06afea33a7677c956b4e173da4a0\" # key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle (https://www.kaggle.com/c/dogs-vs-cats/data)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "test1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwIL8d1n7eS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19408409-7531-4a25-92f2-a4ca29cbcca3"
      },
      "source": [
        "# Unzip training data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/train.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa2Bj5i7pPKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c4e092-cb46-46f9-dcbf-0f9344e74c1a"
      },
      "source": [
        "# Get all the paths\n",
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ERlHkfHqpK8"
      },
      "source": [
        "# Make new base directory\n",
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "#os.mkdir(base_dir)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANB1UJ6rQhM"
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "#os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "#os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "#os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "#os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "#os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "#os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "#os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "#os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "#os.mkdir(test_dogs_dir)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULRgL9s9rV8T"
      },
      "source": [
        "import shutil\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3XAbIyr7vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d664a6-56ba-4cb3-8c03-b93b840fb07a"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yTA21_r-ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33602e04-4b4c-4c20-94e8-9b33097e2123"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mG8wekxsBVS"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zS4Klm8qWp6"
      },
      "source": [
        "## Using ImageDataGenerator to read images from directories\n",
        "As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RGB grids of pixels.\n",
        "* Convert these into floating-point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ7XU7t9sEh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd7d210-5e0f-4393-a1ff-619659ad2411"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgLywySqm4u"
      },
      "source": [
        "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the generator—that is, after having run for `steps_per_epoch` gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
        "\n",
        "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMyfPphJsJG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9249e159-69e7-417a-8c6a-fc02043f9829"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 10s 92ms/step - loss: 0.7030 - acc: 0.5017 - val_loss: 0.6877 - val_acc: 0.4700\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6791 - acc: 0.5826 - val_loss: 0.7142 - val_acc: 0.4850\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6293 - acc: 0.6547 - val_loss: 0.6264 - val_acc: 0.6500\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5836 - acc: 0.7042 - val_loss: 0.6438 - val_acc: 0.6250\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5411 - acc: 0.7126 - val_loss: 0.6648 - val_acc: 0.6050\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.5403 - acc: 0.7170 - val_loss: 0.5936 - val_acc: 0.6750\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4925 - acc: 0.7548 - val_loss: 0.6244 - val_acc: 0.6500\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4856 - acc: 0.7546 - val_loss: 0.4952 - val_acc: 0.7500\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4540 - acc: 0.7970 - val_loss: 0.6171 - val_acc: 0.6800\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4444 - acc: 0.7922 - val_loss: 0.5552 - val_acc: 0.7400\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3985 - acc: 0.8300 - val_loss: 0.5790 - val_acc: 0.7200\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3616 - acc: 0.8390 - val_loss: 0.5169 - val_acc: 0.7150\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3524 - acc: 0.8496 - val_loss: 0.6139 - val_acc: 0.7350\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3306 - acc: 0.8608 - val_loss: 0.5867 - val_acc: 0.7150\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3003 - acc: 0.8777 - val_loss: 0.6163 - val_acc: 0.7250\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2807 - acc: 0.8835 - val_loss: 0.5309 - val_acc: 0.7400\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2742 - acc: 0.8888 - val_loss: 0.5883 - val_acc: 0.7500\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2440 - acc: 0.8990 - val_loss: 0.6206 - val_acc: 0.7100\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2348 - acc: 0.9030 - val_loss: 0.5394 - val_acc: 0.7550\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2113 - acc: 0.9188 - val_loss: 0.6336 - val_acc: 0.7150\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1968 - acc: 0.9348 - val_loss: 0.6776 - val_acc: 0.7050\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1773 - acc: 0.9433 - val_loss: 0.6989 - val_acc: 0.7050\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1548 - acc: 0.9451 - val_loss: 0.6595 - val_acc: 0.7600\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1426 - acc: 0.9502 - val_loss: 0.8263 - val_acc: 0.7250\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1274 - acc: 0.9558 - val_loss: 0.7661 - val_acc: 0.7400\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1171 - acc: 0.9635 - val_loss: 0.7569 - val_acc: 0.7650\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.0926 - acc: 0.9712 - val_loss: 0.7898 - val_acc: 0.7350\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0997 - acc: 0.9669 - val_loss: 0.9752 - val_acc: 0.7250\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0667 - acc: 0.9766 - val_loss: 0.9312 - val_acc: 0.7000\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.0681 - acc: 0.9762 - val_loss: 0.8844 - val_acc: 0.7200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZaZ2HWZsNUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "c8591adb-1b08-4e3c-8c68-fa2ee5a06264"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5yN5fr48c/lnEhyKDkNFXY5G0kqlHakECmzp5AdsjuqSEe2tr3b5du3X99OXx1VCt9d2So6GUInpyRCKYSEyGmPwzDX74/7GZax1pp1nHWY6/16zWvWetZzuJ/1zFzrXtd9P/ctqooxxpjUVyrRBTDGGBMbFtCNMSZNWEA3xpg0YQHdGGPShAV0Y4xJExbQjTEmTVhAN36JyEwRGRDrdRNJRNaJSJc47FdF5Ezv8XMi8mAo60ZwnGwR+SjScgbZbycR2Rjr/ZriVybRBTCxIyJ7fZ5WBA4Ah73nQ1V1Uqj7UtVu8Vg33anqTbHYj4hkAGuBsqp6yNv3JCDka2hKHgvoaURVKxU8FpF1wI2q+knh9USkTEGQMMakD0u5lAAFX6lF5B4R+RV4WUSqish7IrJNRH73Htfx2WaOiNzoPR4oIvNFZLy37loR6Rbhug1EZK6I7BGRT0TkaRF5PUC5QynjwyLymbe/j0Skus/r14vIehHZLiL3B3l/2onIryJS2mfZVSKyzHt8roh8ISI7RWSziDwlIuUC7OsVEfmbz/MR3ja/iMigQut2F5GvRWS3iGwQkTE+L8/1fu8Ukb0i0r7gvfXZ/nwRWSgiu7zf54f63gQjIn/wtt8pIitEpIfPa5eLyHfePjeJyN3e8ure9dkpIjtEZJ6IWHwpZvaGlxynAacA9YEhuGv/sve8HrAPeCrI9u2A1UB14FHgRRGRCNZ9A1gAVAPGANcHOWYoZfwTcANQEygHFASYs4Fnvf2f7h2vDn6o6lfAf4CLC+33De/xYWC4dz7tgUuAvwQpN14ZunrluRQ4Cyicv/8P0B84GegODBORXt5rF3m/T1bVSqr6RaF9nwK8DzzpndvjwPsiUq3QORz33hRR5rLAu8BH3na3ApNEpLG3you49F1loCmQ4y2/C9gI1ABOBe4DbFyRYmYBveTIB0ar6gFV3aeq21X1LVXNVdU9wDigY5Dt16vq86p6GJgI1ML944a8rojUA9oCD6nqQVWdD0wPdMAQy/iyqn6vqvuAqUBLb/nVwHuqOldVDwAPeu9BIG8CWQAiUhm43FuGqi5W1S9V9ZCqrgP+1085/LnGK99yVf0P7gPM9/zmqOq3qpqvqsu844WyX3AfAD+o6mteud4EVgFX+qwT6L0J5jygEvCId41ygPfw3hsgDzhbRE5S1d9VdYnP8lpAfVXNU9V5agNFFTsL6CXHNlXdX/BERCqKyP96KYnduK/4J/umHQr5teCBquZ6DyuFue7pwA6fZQAbAhU4xDL+6vM416dMp/vu2wuo2wMdC1cb7y0i5YHewBJVXe+Vo5GXTvjVK8ffcbX1ohxTBmB9ofNrJyKzvZTSLuCmEPdbsO/1hZatB2r7PA/03hRZZlX1/fDz3W8f3IfdehH5VETae8sfA9YAH4nITyIyKrTTMLFkAb3kKFxbugtoDLRT1ZM4+hU/UBolFjYDp4hIRZ9ldYOsH00ZN/vu2ztmtUArq+p3uMDVjWPTLeBSN6uAs7xy3BdJGXBpI19v4L6h1FXVKsBzPvstqnb7Cy4V5asesCmEchW137qF8t9H9quqC1W1Jy4dMw1X80dV96jqXaraEOgB3Ckil0RZFhMmC+glV2VcTnqnl48dHe8DejXeRcAYESnn1e6uDLJJNGX8F3CFiFzgNWCOpei/9zeA23EfHP9XqBy7gb0i0gQYFmIZpgIDReRs7wOlcPkr476x7BeRc3EfJAW24VJEDQPsewbQSET+JCJlRORa4GxceiQaX+Fq8yNFpKyIdMJdo8neNcsWkSqqmod7T/IBROQKETnTayvZhWt3CJbiMnFgAb3kegI4AfgN+BL4oJiOm41rWNwO/A2Ygusv70/EZVTVFcDNuCC9Gfgd12gXTEEOO0dVf/NZfjcu2O4BnvfKHEoZZnrnkINLR+QUWuUvwFgR2QM8hFfb9bbNxbUZfOb1HDmv0L63A1fgvsVsB0YCVxQqd9hU9SAugHfDve/PAP1VdZW3yvXAOi/1dBPueoJr9P0E2At8ATyjqrOjKYsJn1i7hUkkEZkCrFLVuH9DMCbdWQ3dFCsRaSsiZ4hIKa9bX09cLtYYEyW7U9QUt9OAt3ENlBuBYar6dWKLZEx6sJSLMcakCUu5GGNMmkhYyqV69eqakZGRqMMbY0xKWrx48W+qWsPfawkL6BkZGSxatChRhzfGmJQkIoXvED6iyJSLiLwkIltFZHmA10VEnhSRNSKyTERaR1NYY4wxkQklh/4K0DXI691wNxWchRvF79noi2WMMSZcRQZ0VZ0L7AiySk/gVXW+xA2eVCtWBTTGGBOaWOTQa3PsiHIbvWWbC68oIkNwtXjq1Ss8ThHk5eWxceNG9u/ff9xrJrlUqFCBOnXqULZs2UQXxRjjKdZGUVWdAEwAyMzMPK4D/MaNG6lcuTIZGRkEnjvBJJqqsn37djZu3EiDBg0SXRxjjCcW/dA3cewQoXWIcAjP/fv3U61aNQvmSU5EqFatmn2TMibJxCKgTwf6e71dzgN2qepx6ZZQWTBPDXadjEk+RaZcRORNoBNQXUQ24sZ0Lgugqs/hxmW+HDc8aC5uDkNjjElpqjB1KnToAHX8zkabfELp5ZKlqrVUtayq1lHVF1X1OS+Y4/VuuVlVz1DVZqqasncLbd++nZYtW9KyZUtOO+00ateufeT5wYMHg267aNEibrvttiKPcf755xe5TijmzJnDFVdcEZN9GWOOt3w59OsH550H332X6NKEJqXHcpk0CTIyoFQp93vSpOj2V61aNZYuXcrSpUu56aabGD58+JHn5cqV49ChQwG3zczM5MknnyzyGJ9//nl0hTTGFIscbzqSgwfhwgvhyy8TW55QpGxAnzQJhgyB9evdV6P1693zaIN6YQMHDuSmm26iXbt2jBw5kgULFtC+fXtatWrF+eefz+rVq4Fja8xjxoxh0KBBdOrUiYYNGx4T6CtVqnRk/U6dOnH11VfTpEkTsrOzKRj5csaMGTRp0oQ2bdpw2223FVkT37FjB7169aJ58+acd955LFu2DIBPP/30yDeMVq1asWfPHjZv3sxFF11Ey5Ytadq0KfPmzYvtG2ZMmpg1C848E776CqpWhUsugQ8/THSpgkvZ8dDvvx9yc49dlpvrlmdn+98mUhs3buTzzz+ndOnS7N69m3nz5lGmTBk++eQT7rvvPt56663jtlm1ahWzZ89mz549NG7cmGHDhh3XZ/vrr79mxYoVnH766XTo0IHPPvuMzMxMhg4dyty5c2nQoAFZWVlFlm/06NG0atWKadOmkZOTQ//+/Vm6dCnjx4/n6aefpkOHDuzdu5cKFSowYcIELrvsMu6//34OHz5MbuE30RjDoUPw6aeQlQUNGsBnn0HXrnDllfDqqy4Vk4xSNqD//HN4y6PRt29fSpcuDcCuXbsYMGAAP/zwAyJCXl6e3226d+9O+fLlKV++PDVr1mTLli3UKdSycu655x5Z1rJlS9atW0elSpVo2LDhkf7dWVlZTJgwIWj55s+ff+RD5eKLL2b79u3s3r2bDh06cOedd5KdnU3v3r2pU6cObdu2ZdCgQeTl5dGrVy9atmwZ1XtjTDpasgR274aLL3bPTz0V5syBHj3gT3+C7dvh5psTWkS/Ujbl4udG06DLo3HiiSceefzggw/SuXNnli9fzrvvvhuwL3b58uWPPC5durTf/Hso60Rj1KhRvPDCC+zbt48OHTqwatUqLrroIubOnUvt2rUZOHAgr776akyPaUw6KMifd+p0dFmVKvDBB66WfsstMGaMS/cmk5QN6OPGQcWKxy6rWNEtj6ddu3ZRu3ZtAF555ZWY779x48b89NNPrFu3DoApU4qeYP7CCy9kktd4MGfOHKpXr85JJ53Ejz/+SLNmzbjnnnto27Ytq1atYv369Zx66qkMHjyYG2+8kSVLlsT8HIxJdbNmQbNmULPmsctPOAHeegtuuAH++lcX2A8fTkwZ/UnZgJ6dDRMmQP36IOJ+T5gQ+/x5YSNHjuTee++lVatWMa9RA5xwwgk888wzdO3alTZt2lC5cmWqVKkSdJsxY8awePFimjdvzqhRo5g4cSIATzzxBE2bNqV58+aULVuWbt26MWfOHFq0aEGrVq2YMmUKt99+e8zPwZhUduAAzJ9/NN1SWJky8OKLMGIEPPOMizlF9GouNgmbUzQzM1MLT3CxcuVK/vCHPySkPMlk7969VKpUCVXl5ptv5qyzzmL48OGJLtZx7HqZdPTppy7VMn26S68E89hjMHIkXHopvP02eJ3Y4kpEFqtqpr/XUraGns6ef/55WrZsyTnnnMOuXbsYOnRoootkTImRk+PubbnooqLXHTECXnrJbdOlC/z+e/zLF0zK9nJJZ8OHD0/KGrkxJcGsWZCZ6RpBQ3HDDa6f+jXXuKD+0UdQrVp8yxiI1dCNMcazd6+7kShQ/jyQXr3g3/+GFSvctlu3xqd8RbGAbowxnvnz3U1Fl1wS/rbdusF778EPP0DnzvDrr7EvX1EsoBtjjCcnB8qVg0jH0OvSBWbMcEORdOwImyKaGSJyFtCNMcYzaxa0b3/8PS7h6NTJ3YC0ebML6vG4ez0QC+g+OnfuzIeFRt954oknGDZsWMBtOnXqREH3y8svv5ydO3cet86YMWMYP3580GNPmzaN73zG6HzooYf45JNPwim+XzbMrjGh2bEDvv46/Py5Pxdc4BpHf/vNBfW1a6PfZygsoPvIyspi8uTJxyybPHlySANkgRsl8eSTT47o2IUD+tixY+nSpUtE+zLGhO/TT92t/JHkz/057zxX49+1ywX1NWtis99gLKD7uPrqq3n//fePTGaxbt06fvnlFy688EKGDRtGZmYm55xzDqNHj/a7fUZGBr/99hsA48aNo1GjRlxwwQVHhtgF18e8bdu2tGjRgj59+pCbm8vnn3/O9OnTGTFiBC1btuTHH39k4MCB/Otf/wJg1qxZtGrVimbNmjFo0CAOHDhw5HijR4+mdevWNGvWjFWrVgU9Pxtm15jAcnLgxBOhbdvY7bNNG5g9G/btc/3ai/gXjVrS9kO/4w5YujS2+2zZEp54IvDrp5xyCueeey4zZ86kZ8+eTJ48mWuuuQYRYdy4cZxyyikcPnyYSy65hGXLltG8eXO/+1m8eDGTJ09m6dKlHDp0iNatW9OmTRsAevfuzeDBgwF44IEHePHFF7n11lvp0aMHV1xxBVdfffUx+9q/fz8DBw5k1qxZNGrUiP79+/Pss89yxx13AFC9enWWLFnCM888w/jx43nhhRcCnp8Ns2tMYLNmuYksypWL7X5btHBBvUsXl1+fNQvOOSe2xyhgNfRCfNMuvumWqVOn0rp1a1q1asWKFSuOSY8UNm/ePK666ioqVqzISSedRI8ePY68tnz5ci688EKaNWvGpEmTWLFiRdDyrF69mgYNGtCoUSMABgwYwNy5c4+83rt3bwDatGlzZECvQObPn8/1118P+B9m98knn2Tnzp2UKVOGtm3b8vLLLzNmzBi+/fZbKleuHHTfxqSyzZth5crY5M/9adrUDb9bqpQL6t98E5/jJG0NPVhNOp569uzJ8OHDWbJkCbm5ubRp04a1a9cyfvx4Fi5cSNWqVRk4cGDAYXOLMnDgQKZNm0aLFi145ZVXmDNnTlTlLRiCN5rhd0eNGkX37t2ZMWMGHTp04MMPPzwyzO7777/PwIEDufPOO+nfv39UZTUmWc2e7X7HK6ADNGni8vSXXgqrV7uae6xZDb2QSpUq0blzZwYNGnSkdr57925OPPFEqlSpwpYtW5g5c2bQfVx00UVMmzaNffv2sWfPHt59990jr+3Zs4datWqRl5d3ZMhbgMqVK7Nnz57j9tW4cWPWrVvHGq9F5bXXXqNjx44RnZsNs2uMfzk57vb9eM/3ctZZLo9+zTXx2X/S1tATKSsri6uuuupI6qVguNkmTZpQt25dOnToEHT71q1bc+2119KiRQtq1qxJW59Wlocffph27dpRo0YN2rVrdySI9+vXj8GDB/Pkk08eaQwFqFChAi+//DJ9+/bl0KFDtG3blptuuimi8yqY67R58+ZUrFjxmGF2Z8+eTalSpTjnnHPo1q0bkydP5rHHHqNs2bJUqlTJJsIwaW3WLJcK8SYmi6sKFeK3bxs+10TMrpdJB2vXQsOG8D//4yasSHY2fK4xxgRQMN1cPPPnxcUCujGmRMvJgdNOg3T4spl0AT1RKSATHrtOJh2ouoB+8cVuKstUl1QBvUKFCmzfvt2CRZJTVbZv306FeLbuGFMMVq50w9ymQ7oFkqyXS506ddi4cSPbtm1LdFFMESpUqECdOnUSXQxjopJO+XNIsoBetmxZGjRokOhiGGNKiJwcaNDA/aSDpEq5GGNMcTl82N0hmi61c7CAbowpoZYuhZ07LaAbY0zEcnPdsLKJvvm4IH/euXNiyxFLFtCNMcVq9mxYsgQGD4Yvv0xcOXJyXN/zWrUSV4ZYs4BujClWM2a4OTtr14Y+fVy3weJ28CDMnRu72YmSRUgBXUS6ishqEVkjIqP8vF5PRGaLyNciskxELo99UY0xqU7VBfQuXeCdd+D336FvXxdgi9OCBS71k075cwghoItIaeBpoBtwNpAlImcXWu0BYKqqtgL6Ac/EuqDGmNS3ejWsWwfdurnxwF98EebPh7vuKt5y5OS4O0MjHIk6aYVSQz8XWKOqP6nqQWAy0LPQOgqc5D2uAvwSuyIaY9LFjBnud7du7ndWlgvmTz0Fr7xSfOXIyYFWreCUU4rvmMUhlIBeG9jg83yjt8zXGOA6EdkIzABujUnpjDFpZeZMN59m/fpHlz3yiEt93HQTFBpROy5yc+GLL9Ivfw6xaxTNAl5R1TrA5cBrInLcvkVkiIgsEpFFdnu/MSXL3r1uCraC2nmBMmVgyhQ34mHv3rB1a3zL8dlnLmefbvlzCC2gbwLq+jyv4y3z9WdgKoCqfgFUAKoX3pGqTlDVTFXNrFGjRmQlNsakpFmzIC8PLvfTZaJ6dXj7bdi2zU3PlpcXnzLs2AHjx7sPkQsuiM8xEimUgL4QOEtEGohIOVyj5/RC6/wMXAIgIn/ABXSrghtjjpg5EypVgkAzOLZuDRMmuFr8yJHxOX7Tpi5//l//5cqSbooM6Kp6CLgF+BBYievNskJExopID2+1u4DBIvIN8CYwUG0MXGOMp6C74qWXQrlygde7/nq4/XZ44gl4/fXYHHvPHhgyxH0zqFbNdVm87bbY7DvZJNWcosaY9LR8OTRrBs8/DzfeGHzdvDwX+L/6Cj7/3PVGidS8eTBggOsqOWIEjB0L5ctHvr9kYHOKGmMSauZM97tr16LXLVsWpk51efWrroLffgv/ePv3uwDesaPrbz53Lvzzn6kfzIuSVOOhG2PS04wZ0Lw5hDonSs2arpH0wgvd4FlXXulq6q1aQcOGUCpIVXTJEujfH1asgKFDXSNoOubL/bGAboyJq9273d2gd98d3nZt28KkSS5N8thjcOiQW165srvLtCDAt2zp+raXKgX/+Idbv0YN9yFSuItkurOAboyJq08+ccE4kuDap4/72b/f1bi//tr9LF0KL70E//mPW69sWZei2bzZ3X361FPpdxdoKCygG2PiasYMqFIF2rePfB8VKrgx1Nu0Obrs8GFYs+ZogP/+e+jXz/VjL6ksoBtj4kbVNYj+8Y+uFh1LpUtD48bup1+/2O47VVkvF2NM3CxbBr/8UvJy2YliAd0YEzcFoyuG0l3RRM8CujEmbmbOdD1R0mmat2RmAd0YExc7d7o7Pf0NxmXiwwK6MSYuPv7Y9USxgF58LKAbY+JixgyoWhXatUt0SUqOtA3o+fnw3nuJmVHcmJIuP9/lzy+7zHUvNMUjLQP6J5+4GxCuvBKuu871hTXGFJ+lS2HLFku3FLe0CujLl7s/oEsvdQ0y113nZkn56KNEl8yYkqWgu+JllyW2HCVNSgX0SZMgI8MNwpOR4Z6DG79h8GA3YM8XX7jR1VatghdfdCOzjRzpGmeMMeE7eDD8bWbMcINr1awZ+/KYwFImoE+a5GYdWb/epVDWr3dBvHdvOPNMmDjRzXSyZg3cdZcb97hcOTf62rJlsZv9xJiS4ttvYdAgN7ph//5ugKxQbN/uJqewu0OLX8oE9Pvvh9zcY5ft2wfvvANXXAErV8Ljj7sppnz17etqCg884NY3xgSmCh984MZead4cpkxxaZPXXnOTRfzyS9H7+Ogj1yhq+fPilzIB/eefA782ZQqccYb/10Tg0Udh40b4n/+JT9mMSXX798MLL7hJlLt1c0PV/uMfsGEDTJ/uJptYscJVjhYuDL6vmTPdULaZfidJM/GUMgG9Xj3/y+vXL3rbTp1cLf7vf3dfB40xztat8Ne/uv+vwYNdmvLVV2HtWhg16uiY4ldd5e76LFsWLroI3njD//6su2JipUxAHzcOKlY8dlnFim65P4UbUC+4wM3+HWh9Y0qSn392AbxePRgzxt38k5Pjpm+7/noX2Atr3tzVztu2hexsuO8+F8B9LVrk5gC1dEuCqGpCftq0aaPhev111fr1VUXc79dfD7xexYqqLiPofipWVO3USbVsWdWffgr70MakjW++UT3tNNUKFVSHDlVduTK87Q8cUB082P1fXXml6u7dR18bM8b9f/72W2zLbI4CFmmAuCqaoLtuMjMzddGiRXHZd0aG6wVTWO3asGMH9OoV+CujMels/nyXfqxUCT780M3FGQlVePppuOMOaNLE5dkbNnQ1/VKlXPdhEx8islhV/bZQpEzKJRyBGlB/+QXuvBPefNN9NYyXvDzXUPvII8d/JTUmUd591910d9ppLh8eaTAH19ngllvch8Ivv8C558L//Z9LyVi6JXHSMqAHakCtV8/dZFS9uvsd6y8nO3bAP//pair9+sG998Jzz8X2GMZEYuJE17DZtCnMmxf4fyRcl1wCCxa4G4iuucb9T1lAT5y0DOjBGlBPOglGj4bZs11/21hYuRKGDYM6dVzPgMaN3VfQyy6DESPgxx9jcxxjIjF+PAwcCJ07u4bPGjViu/8zz3Qplp49oVkzN6GFSZBAyfV4/0TSKBqOYA2oBw6onnGGatOmqocORbb//HzVDz5Q7drVNQ6VL6/65z+rLlt2dJ0NG1SrVFG98ELVw4ejORtjwpefrzpypPv7vOYa1f37i+eYJr4I0iiatgG9KFOnurN/6aXwttu7V/XZZ1WbNHHbn3aa6sMPq27d6n/9l1926/33f0ddZGNClpenesMN7m/vL3+JvOJikk+wgJ6WvVxCoQrnnQebNsH33x+fovGVn+96B7z2mmv42bULWreG4cNd3tBfn13f4/To4Yb0/eYbaNQo9udijK99+1wbzvTpro/5Qw+5RkyTHkpcL5dQiMBjj7mAXrv28SM4ggv0Dz7ohhXo2NH1junRA+bOdb1krrsueDAvOM6ECXDCCS6PaaM+mnjaudO13bz7rutWOHq0BfOSpEyiC5BIGza425N37nTPC0Zw/OgjN/zuggUu0HfpAg8/7HoJnHhi+MepVQueesrdXff4466h1JhYO3AALr7YzQswebL79mhKlhKbcoHANyCBG1v9+ushKwtOPz36Y6lCnz5unOglS+Dss6PfpzG+nn7a9Q1/6y03rLRJT8FSLiU6oJcqFbgvejzelq1b3c0cGRmum1eZML4fHT4Mzz7rxnZ/7jlXdmMK7Nvnug+ecQZ8+qmlWdKZ5dADiGYEx0jUrAnPPOPy7//8Z+jbrVjhBhe79VZ4/nnXhz5WVGHv3tjtz4Rm5kzXZztWQ1BMmODu2Hz4YQvmJVmJDujhjuAYC337wrXXuiFLly0Lvu6BA66XQqtW8MMP8NJLUKWKu+svVv7xD5fjL6osibZhg5t1KpLp0ALt7+qr3QiCxfmBtmsX3Hiju5ty5Ur3IR3tkM65ue46Xnyxa7w3JVig/oy+P0BXYDWwBhgVYJ1rgO+AFcAbRe0z0f3QC4Q6gmMsbdumWrOmasuW7iYnfz7/XPXss10/4uzso/3cBw92I0f6jnAXqbw81Vq13DHOPFP199+j32e8XHbZ0XK+807kN7AcPKg6frzqiSe60QZB9aGHYlvWQD7+WLVuXdVSpVRHjVJdsEC1dGnVYcOi2+9jj7nzmD8/NuU0yY1obiwCSgM/Ag2BcsA3wNmF1jkL+Bqo6j2vWdR+kyWgJ8q0ae7dHz362OW7d6veeqv7gKlbV/X99499ff58t93LL8euDPfco1qmjGrPnsl5R+uXX7pyXnfd0Q+5zp1Vv/46vP18/rlq8+Zu++7dVdeuVb32WtUTTnB39cbLnj2qN93kjtu4sTufArfe6gJ8uOfiu+/q1d0HnikZog3o7YEPfZ7fC9xbaJ1HgRuL2pfvT0kP6KouQJUpo7p4sXs+Y4ZqvXoumN96q/9aeH6+q6V26hT98bt3dzX0vDx3JyuoPvJI9PuNtcsvV61WzQWvvDzVp592z0XccAubNwfffvv2o+N316mj+vbbR2v4a9e6YRv6949P2WfPVs3IcGW96y7V3NxjX9+xwwXkCy6I7FvH3//uzsv3Q8Kkt2gD+tXACz7PrweeKrTONC+ofwZ8CXQNsK8hwCJgUb169YrvHUhSO3a4gNq0qeqf/uSuxh/+oPrZZ8G3GzvWrbt2beTH3rDB1Qzvu889z893432UKqU6a1bk+421BQvcuY4bd+zy339XvfNON2FJpUru9cLBMj9fdeJE1Ro1XGrjrrvch0Jh99zjjrFoUezKvXev+1AuSBMFS4c8/7xbL9x0365dqlWrug9mU3IUR0B/D3gHKAs0ADYAJwfbr9XQnfffd1ehbFmXfgllAKV169w2Y8dGftyCD4Uffzy6bPduN0ZNjRrxTUGE48orXdDatRzd39EAABIOSURBVMv/699/r9qrlzuX+vVVJ092gfy771Q7dnTL27d3s/QEsnOnO+eOHWMzuNS8eS6Ig+ptt6n+5z/B1z98WDUz0324h9M2UnANC77hmZKhOFIuzwE3+DyfBbQNtt9UDOjxakB95x3VFSvC26ZzZxc0IglAhw+78nfpcvxr333narzt2wdusC0uixeH/sGVk6PaooVbv3lz9wFZtarqhAmhtQs8+6zb9p13oivz//t/7u+jQQPVOXNC366gnWDEiNDW37HDjeTZq1dk5TSpK9qAXgb4yat5FzSKnlNona7ARO9xda+GXi3YflMtoAeap7Q4esX488orGnHPhg8+cNtOmeL/9SlT3Ou33hpdGaPVq5cLWjt3hrb+oUOqL7zg0lYDBqhu2RL6sfLyXIPrmWdG/kE2fboL5j17+k/tFOWGG9wH0apVRa/74IPuGgX75mHSU1QB3W3P5cD3Xm+X+71lY4Ee3mMBHve6LX4L9Ctqn6kW0OvXPzaYF/zUr5+Y8uzZ47reDR4c/rZ9+riGuGDpnTvucOf3xhvh7fuXX1SHD1ft0SOyoFZg6VL12wsonmbM0IiHOl62zH2zadOm6BRLIL/+qnrSSa7HSrBvXr/9plq5smrfvpEdx6S2qAN6PH5SLaCL+A/oIokrU//+LgAUbgwMZssW17PmzjuDr3fwoOt5UbGi6vLlRe930yaXL65QwTVAiqhmZUWek+7Tx53bjh2RbR+J/HzVP/7RpWq2bw99uy1b3Ad7rVqqGzdGV4aC3kbTpgVeZ9Qo9/6Gcl1M+rGAHgPJVkNXdb1RQPXNN0Pf5tFH3TbffVf0ups2qZ56qmqjRoEbJTdsUL3lFtf1r3Rp1UGDVNesUf3b39xxnnoq9LIVWLbMbfvAA+FvG61ly1xPn9tvD239/ftVzz/ffZAtXBj98Q8eVD3nHNfV0d8H9ZYt7ptZVlb0xzKpyQJ6DCRbDl3VNfbVq+emwQtFfr4LzhdcEPox5sxxgbpPn2Nr2+vXuzscy5VzNf4bb1T96adjy9a9u8sJf/FF6MdTdd0nK1cOr5YcS0OGuHNavTr4evn57ltSsPaISOTkuH3+9a/Hv3b33e4DJ5Q8u0lPFtBjJBHDBBTl/vvdP/imTUWvO2eOu+ITJ4Z3jIJby8ePd10mhw51gbpsWfc4UH/4HTtcTbNOncBT9BW2YoV7fwv6xyfCr7+6fHhRPUgeeSRw4I1W376u1r9u3dFlmze7u1rjdROUSQ0W0ItZcQb+1avdVXz00aLXzc52vUbCbbTLz1ft3dvV1MuUcbXyYcNcLb0oixe7dMyll4Y2r2VWlkspbNsWXhljreAOzNmz/b8+bZq7vv36xWdi5PXrXfDu0+fosttvd9fghx9ifzyTOiygF6NEpGbat3d512CBZccOF1j/8pfIjrFrl+t9cfPN4d90VHAn5IMPBl9v5UoXJO+5J7IyxlJurktntWp1fD/2pUvdh07btuE1SIfr4Yfd+/bxx66xtXx510ZhSjYL6MUoEY2nzz3njhGsUe7JJ906kQ4CFY38/KMz0L/3XuD1rrvOffiFmp6Jt0mTXJlfeeXoss2b3aBptWu7LprxtG+fasOGrl99QV4/muEeTHqwgF6MEtG98fffXe3tllv8v56fr9qsmbu9PFFyc92dnFWr+g9Kq1e7toC77y72ogV0+LDquee64L13rwuw553nUiHFdbv99OlH/4aGDi2eY5rkFiygl+gJLuIh0CxIgZbHwsknQ8+e8Oab/ieAWLAAvv3WTYCdKCec4Oa6zM93E0vs33/s6+PGQfnycPfdiSmfP6VKuUm9N22C8ePdxBRffgmvvQatWxdPGa64wk2GUb483Hdf8RzTpLBAkT7eP+laQw83hx6rBtSCQb7efvv41/78Z1eGQH3Ji9O//+3KOWTI0WU//OAa+4YPT1y5gunb9+g3r7/9rfiPn5vrBiEzRtVSLsUu1CAdywbUvDzV005z44j42r3bNeAlU2Pavfe6cy2YpOOGG1wXvXjnpCP144/uPczOjk+PFmPCYQE9ScW6AfXuu13DmW+j4oQJbp/h3twTT3l5brTIChXc6IalS7thA5LZjh0WzE1yCBbQLYeeQD//HN7yogwYAIcOuVx6geefh6ZNoV27yPYZD2XKuDKecgpcdZV7fs89iS5VcFWrgkiiS2FMcBbQEyjWDahNm7rGuokT3fNvvoGFC11jaLIFo1NPhalTXTAfOhROPz3RJTIm9VlAT6Bx46BixWOXVazolhc2aRJkZLieFxkZ7rk/AwbAkiWwfLmrnZcvD9ddF+uSx0aHDrBunetJYoyJngX0BMrOhgkToH59V4OuX989z84+dr1Jk2DIEFi/3mXZ1693z/0F9awsV+t97jl4/XXo08elNpJV7dpQunSiS2FMehCXYy9+mZmZumjRooQcO9VkZLggXlj9+q6GW1ivXvDvf7vHs2dDp05xLJwxpliJyGJVzfT3mtXQU0C4jacDBrjfZ50FHTvGp0zGmORjAT0FhNt42r07tGgBI0YkX2OoMSZ+LKCngHAaTwHKlYOlSxN7q78xpvhZQE8BoTaeGmNKNgvoKSI72zWA5ue738GCeahdHI0x6aVMogtgYqugi2Nurnte0MURrEZvTLqzGnqauf/+o8G8QG6uW26MSW8W0NNMrMeHMcakDgvoaSacLo6WazcmvVhATzOhdnEMZzgBY0xqsICeZkLt4mi5dmPSj43lUkKVKuVq5oWJuK6RxpjkZGO5mOMkYjJrY0x8WUAvocIdTsAYk/wsoJdQ4Q4nYD1ijEl+dqdoCZadHdrdo3b3qTGpwWropkjWI8aY1GAB3RTJ7j41JjVYQDdFsh4xxqSGkAK6iHQVkdUiskZERgVZr4+IqIj47SNpUpP1iDEmNRQZ0EWkNPA00A04G8gSkbP9rFcZuB34KtaFNIllE2wYkxpCqaGfC6xR1Z9U9SAwGejpZ72HgX8C+2NYPpMkQp1gw7o3GpM4oQT02sAGn+cbvWVHiEhroK6qvh9sRyIyREQWiciibdu2hV1Yk9xswC9jEivqRlERKQU8DtxV1LqqOkFVM1U1s0aNGtEe2iQZ695oTGKFEtA3AXV9ntfxlhWoDDQF5ojIOuA8YLo1jJY84XZvtPSMMbEVSkBfCJwlIg1EpBzQD5he8KKq7lLV6qqaoaoZwJdAD1W1oRRLmHAn17D0jDGxVWRAV9VDwC3Ah8BKYKqqrhCRsSLSI94FNKkjnO6Nlp4xJvZsPHQTU5MmuaD888+uZj5unP8eMTYeuzGRCTYeug3OZWIq1AG/6tVzaRZ/y40xkbFb/01ChJOescZTY0JjAd0kRKh3n1rjqTGhsxy6SWoZGf5TM/XruztWjSlpbE5Rk7Js6F5jQmcB3SQ1G7rXmNBZQDdJLdyhe60B1ZRkFtBNUgtn6F5rQDUlnTWKmrRhDaimJLBGUVMiWAOqKeksoJu0Ee7gYJZrN+nGArpJG6E2oFqu3aQrC+gmbYTagGojPZp0ZY2ipsSxkR5NKrNGUWN8hHuzkuXbTaqwgG5KnHBHerR8u0kVFtBNiRPOzUqWbzepxHLoxgRh+XaTbCyHbkyEbHAwk0osoBsThM2sZFKJBXRjgrCZlUwqsRy6MTFgA4OZ4mI5dGPizAYGM8nAAroxMWA3K5lkYAHdmBiwm5VMMrCAbkwM2M1KJhlYQDcmRrKzXQNofr777S+YQ3j5dkvNmHBYQDemmIWab7fUjAmXBXRjilmo+XZLzZhwWUA3ppiFmm+3rpAmXBbQjUmAUPLt1hXShMsCujFJyrpCmnBZQDcmSVlXSBMuG8vFmDRg47aXHDaWizFpzsZtNxBiQBeRriKyWkTWiMgoP6/fKSLficgyEZklIvVjX1RjTCA2bruBEAK6iJQGnga6AWcDWSJydqHVvgYyVbU58C/g0VgX1BgTmI3bbiCEHLqItAfGqOpl3vN7AVT1HwHWbwU8paodgu3XcujGFD8btz31RZtDrw1s8Hm+0VsWyJ+BmQEKMkREFonIom3btoVwaGNMLNnNSuktpo2iInIdkAk85u91VZ2gqpmqmlmjRo1YHtoYEwJrPE1voQT0TUBdn+d1vGXHEJEuwP1AD1U9EJviGWNiKZzGU7AG1FQTSkBfCJwlIg1EpBzQD5juu4KXN/9fXDDfGvtiGmNiIZyblawBNfWEdGORiFwOPAGUBl5S1XEiMhZYpKrTReQToBmw2dvkZ1XtEWyf1ihqTHKzBtTkFPWNRao6Q1UbqeoZqjrOW/aQqk73HndR1VNVtaX3EzSYG2OSn03EkXrsTlFjjF82EUfqsYBujPHLJuJIPRbQjTF+2UQcqccCujEmIJuII7VYQDfGRMUm4kgeFtCNMVGxiTiShwV0Y0zUQknNgHWFjDcL6MaYYmNdIePLAroxptjEqyuk1eYdC+jGmGITj66QVps/yiaJNsYknXDGkSlpY87YJNHGmJQSTldIu7HpKAvoxpikE05XSJu04ygL6MaYpBRqV8hwJ+1IZxbQjTEpLdxJO9K5N4wFdGNMygulNh9ub5hUDP4W0I0xJUI4fdtTtSukBXRjTIkQTm+YVB1zxgK6MaZECKc3TKqOOWMB3RhTIoTTGyZeY87EO/hbQDfGlAjh9IaJx5gzxZGXt1v/jTHGj0mTXGD++WdXMx837vjgX6qUC86FibgeN75iNURBsFv/y4S+G2OMKTmyswPfzFSgXj3/QTravHykLOVijDERikdePhoW0I0xJkLxyMtHw1IuxhgThVBSMwXrQdF5+WhYQDfGmGISavCPlKVcjDEmTVhAN8aYNGEB3Rhj0oQFdGOMSRMW0I0xJk0k7NZ/EdkGFL7HqjrwWwKKEy/pdj6QfueUbucD6XdO6XY+EN051VfVGv5eSFhA90dEFgUaoyAVpdv5QPqdU7qdD6TfOaXb+UD8zslSLsYYkyYsoBtjTJpItoA+IdEFiLF0Ox9Iv3NKt/OB9DundDsfiNM5JVUO3RhjTOSSrYZujDEmQhbQjTEmTSRFQBeRriKyWkTWiMioRJcnFkRknYh8KyJLRSQl59oTkZdEZKuILPdZdoqIfCwiP3i/qyayjOEIcD5jRGSTd52WisjliSxjOESkrojMFpHvRGSFiNzuLU/laxTonFLyOolIBRFZICLfeOfzV295AxH5yot5U0SkXEyOl+gcuoiUBr4HLgU2AguBLFX9LqEFi5KIrAMyVTVlb4gQkYuAvcCrqtrUW/YosENVH/E+fKuq6j2JLGeoApzPGGCvqo5PZNkiISK1gFqqukREKgOLgV7AQFL3GgU6p2tIweskIgKcqKp7RaQsMB+4HbgTeFtVJ4vIc8A3qvpstMdLhhr6ucAaVf1JVQ8Ck4GeCS6TAVR1LrCj0OKewETv8UTcP1tKCHA+KUtVN6vqEu/xHmAlUJvUvkaBziklqbPXe1rW+1HgYuBf3vKYXaNkCOi1gQ0+zzeSwhfQhwIfichiERmS6MLE0Kmqutl7/CtwaiILEyO3iMgyLyWTMukJXyKSAbQCviJNrlGhc4IUvU4iUlpElgJbgY+BH4GdqnrIWyVmMS8ZAnq6ukBVWwPdgJu9r/tpRV2+LtX7vT4LnAG0BDYD/5XY4oRPRCoBbwF3qOpu39dS9Rr5OaeUvU6qelhVWwJ1cBmJJvE6VjIE9E1AXZ/ndbxlKU1VN3m/twLv4C5kOtji5TkL8p1bE1yeqKjqFu8fLh94nhS7Tl5e9i1gkqq+7S1O6Wvk75xS/ToBqOpOYDbQHjhZRAqmAI1ZzEuGgL4QOMtr9S0H9AOmJ7hMURGRE70GHUTkROCPwPLgW6WM6cAA7/EA4N8JLEvUCgKf5ypS6Dp5DW4vAitV9XGfl1L2GgU6p1S9TiJSQ0RO9h6fgOv8sRIX2K/2VovZNUp4LxcArwvSE0Bp4CVVHZfgIkVFRBriauXgJuJ+IxXPSUTeBDrhhvrcAowGpgFTgXq44Y+vUdWUaGgMcD6dcF/jFVgHDPXJPyc1EbkAmAd8C+R7i+/D5ZxT9RoFOqcsUvA6iUhzXKNnaVwFeqqqjvVixGTgFOBr4DpVPRD18ZIhoBtjjIleMqRcjDHGxIAFdGOMSRMW0I0xJk1YQDfGmDRhAd0YY9KEBXRjjEkTFtCNMSZN/H84J6tBkF63RQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZmXmBcq_8-"
      },
      "source": [
        "## Convolutional Networks with Dropout\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/ee6fa1073247cd2c3d241300caf110d7a7541bc5/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4972644a355067684439596f4f7956415137334d4a772e676966)\n",
        "\n",
        "Ref: https://github.com/mneha4/Training-Neural-Nets---Guidelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu3cqeYQrDeN"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSeLpvY0rH7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74ec584-80e8-4e26-8a84-ee044599e935"
      },
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 63/100 [=================>............] - ETA: 10s - loss: 0.6951 - acc: 0.4841WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 22s 209ms/step - loss: 0.6946 - acc: 0.4871 - val_loss: 0.6865 - val_acc: 0.5010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdU5yrkUF_b"
      },
      "source": [
        "# Task 2:\n",
        "\n",
        "We have used Dropout to enhance the performance of the CNN model. Can you please use whatever you like to further enhance the performance from `val_acc: 0.7506`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PTZImKhwbvc",
        "outputId": "90509105-0ae3-4e68-caaf-64751dbcf353"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   shear_range=0.1,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=10,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=10,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyc1VnNFwh9H"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhtAHoNEwpYV",
        "outputId": "8e9d32cb-be00-4103-d032-86f8a6fbcf21"
      },
      "source": [
        "import keras \n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('models/best_cat_dog.h5', \n",
        "                                             monitor='val_accuracy', \n",
        "                                             verbose=1, \n",
        "                                             save_best_only=True, \n",
        "                                             mode='max')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                              # steps_per_epoch=100,\n",
        "                              epochs=50,\n",
        "                              validation_data=validation_generator,\n",
        "                              callbacks=[checkpoint])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 24s 113ms/step - loss: 1.3686 - accuracy: 0.5538 - val_loss: 0.6900 - val_accuracy: 0.5040\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50400, saving model to models/best_cat_dog.h5\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6812 - accuracy: 0.5810 - val_loss: 0.7607 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.50400\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6706 - accuracy: 0.6166 - val_loss: 1.0441 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.50400\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6673 - accuracy: 0.5727 - val_loss: 1.4477 - val_accuracy: 0.5030\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.50400\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6355 - accuracy: 0.6188 - val_loss: 0.7681 - val_accuracy: 0.5320\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.50400 to 0.53200, saving model to models/best_cat_dog.h5\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6060 - accuracy: 0.6523 - val_loss: 0.6478 - val_accuracy: 0.6400\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.53200 to 0.64000, saving model to models/best_cat_dog.h5\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6257 - accuracy: 0.6404 - val_loss: 0.6849 - val_accuracy: 0.5200\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.64000\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.6253 - accuracy: 0.6450 - val_loss: 0.6135 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.64000 to 0.67000, saving model to models/best_cat_dog.h5\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 23s 112ms/step - loss: 0.5837 - accuracy: 0.6866 - val_loss: 0.5946 - val_accuracy: 0.6960\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.67000 to 0.69600, saving model to models/best_cat_dog.h5\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.5692 - accuracy: 0.6962 - val_loss: 0.6101 - val_accuracy: 0.6880\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.69600\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.5545 - accuracy: 0.7102 - val_loss: 0.8250 - val_accuracy: 0.5620\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.69600\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.5809 - accuracy: 0.7006 - val_loss: 0.6056 - val_accuracy: 0.6230\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.69600\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.5582 - accuracy: 0.7146 - val_loss: 0.6029 - val_accuracy: 0.7110\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.69600 to 0.71100, saving model to models/best_cat_dog.h5\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.5542 - accuracy: 0.7267 - val_loss: 0.5382 - val_accuracy: 0.7140\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.71100 to 0.71400, saving model to models/best_cat_dog.h5\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.5223 - accuracy: 0.7263 - val_loss: 0.5150 - val_accuracy: 0.7470\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.71400 to 0.74700, saving model to models/best_cat_dog.h5\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.5230 - accuracy: 0.7279 - val_loss: 0.5240 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.74700\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4834 - accuracy: 0.7570 - val_loss: 0.5261 - val_accuracy: 0.7260\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.74700\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.5059 - accuracy: 0.7488 - val_loss: 0.6143 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.74700\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4972 - accuracy: 0.7578 - val_loss: 0.4972 - val_accuracy: 0.7660\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.74700 to 0.76600, saving model to models/best_cat_dog.h5\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4897 - accuracy: 0.7609 - val_loss: 0.5711 - val_accuracy: 0.7200\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.76600\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4963 - accuracy: 0.7597 - val_loss: 0.5300 - val_accuracy: 0.7360\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.76600\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4601 - accuracy: 0.7751 - val_loss: 0.5899 - val_accuracy: 0.7430\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.76600\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4579 - accuracy: 0.7915 - val_loss: 0.4564 - val_accuracy: 0.7750\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.76600 to 0.77500, saving model to models/best_cat_dog.h5\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4552 - accuracy: 0.7794 - val_loss: 0.6176 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.77500\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 0.4612 - accuracy: 0.7840 - val_loss: 0.5143 - val_accuracy: 0.7840\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.77500 to 0.78400, saving model to models/best_cat_dog.h5\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4565 - accuracy: 0.7902 - val_loss: 0.5397 - val_accuracy: 0.7390\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.78400\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4413 - accuracy: 0.8004 - val_loss: 0.6907 - val_accuracy: 0.6850\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.78400\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4509 - accuracy: 0.7955 - val_loss: 0.5212 - val_accuracy: 0.7690\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.78400\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4209 - accuracy: 0.8137 - val_loss: 0.4813 - val_accuracy: 0.7980\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.78400 to 0.79800, saving model to models/best_cat_dog.h5\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4338 - accuracy: 0.7855 - val_loss: 0.4658 - val_accuracy: 0.7810\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.79800\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4347 - accuracy: 0.8040 - val_loss: 0.6387 - val_accuracy: 0.7100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.79800\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4020 - accuracy: 0.8185 - val_loss: 0.4694 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.79800 to 0.80300, saving model to models/best_cat_dog.h5\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4210 - accuracy: 0.8106 - val_loss: 0.4268 - val_accuracy: 0.8080\n",
            "\n",
            "Epoch 00033: val_accuracy improved from 0.80300 to 0.80800, saving model to models/best_cat_dog.h5\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.4087 - accuracy: 0.8012 - val_loss: 0.5797 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.80800\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4130 - accuracy: 0.8165 - val_loss: 0.4752 - val_accuracy: 0.7860\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.80800\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3957 - accuracy: 0.8229 - val_loss: 0.3929 - val_accuracy: 0.8160\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.80800 to 0.81600, saving model to models/best_cat_dog.h5\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3884 - accuracy: 0.8189 - val_loss: 0.6928 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.81600\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3910 - accuracy: 0.8270 - val_loss: 0.4686 - val_accuracy: 0.7950\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.81600\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.3868 - accuracy: 0.8349 - val_loss: 0.5870 - val_accuracy: 0.7410\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.81600\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.4060 - accuracy: 0.8169 - val_loss: 0.4965 - val_accuracy: 0.7590\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.81600\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3829 - accuracy: 0.8314 - val_loss: 0.5048 - val_accuracy: 0.7550\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.81600\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3549 - accuracy: 0.8606 - val_loss: 0.5180 - val_accuracy: 0.7550\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.81600\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3656 - accuracy: 0.8526 - val_loss: 0.4488 - val_accuracy: 0.8110\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.81600\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3646 - accuracy: 0.8547 - val_loss: 0.3725 - val_accuracy: 0.8290\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.81600 to 0.82900, saving model to models/best_cat_dog.h5\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.3362 - accuracy: 0.8502 - val_loss: 0.4192 - val_accuracy: 0.8100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.82900\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3311 - accuracy: 0.8511 - val_loss: 0.5582 - val_accuracy: 0.7340\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.82900\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.3381 - accuracy: 0.8557 - val_loss: 0.4695 - val_accuracy: 0.7890\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.82900\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3178 - accuracy: 0.8580 - val_loss: 0.4333 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.82900\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 23s 113ms/step - loss: 0.3342 - accuracy: 0.8475 - val_loss: 0.3796 - val_accuracy: 0.8410\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.82900 to 0.84100, saving model to models/best_cat_dog.h5\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 23s 114ms/step - loss: 0.3006 - accuracy: 0.8759 - val_loss: 0.3875 - val_accuracy: 0.8250\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.84100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}